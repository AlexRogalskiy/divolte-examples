divolte {
  kafka_flusher {
    enabled = false
    threads = 1
  }

  hdfs_flusher {
    enabled = true

    threads = 1

    hdfs {
      // Point to your HDFS NameNode here.
      // In case of multiple NameNode's or other configuration,
      // you can leave out this configuration altogether and
      // make sure there is a HADOOP_CONF_DIR on the Divolte 
      // classpath.
      uri = "hdfs://127.0.0.1:8020/"

      // Set to a higher value for production use.
      replication = 1
    }

    simple_rolling_file_strategy {
      // For the example's sake, we roll files very quickly.
      // In a production scenario, you would rather set this
      // to something on the order of one hour.
      roll_every = 60 seconds

      // Syncing files requires flushing, network traffic and coordination.
      // Also, it will write a Avro block boundary, which could lead to
      // inefficiencies when there are too many. In production, syncing should
      // be set to happen once every 1000 records or more and perhaps once
      // every 30 seconds.
      sync_file_after_records = 100
      sync_file_after_duration = 5 seconds

      // Make sure these directories exist in HDFS, or Divolte will not start.
      working_dir = "/divolte/inflight"
      publish_dir = "/divolte/published"
    }
  }
  
  javascript {
    logging = true
    debug = true
  }

  tracking {
    schema_file = /path/to/divolte-examples/avro-schema/src/main/resources/JavadocEventRecord.avsc
  }
}

include file("/path/to/code/divolte-examples/avro-schema/mapping.conf")
